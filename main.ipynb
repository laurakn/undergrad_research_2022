{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurakn/undergrad_research_2022/blob/ruoyu/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the parameters"
      ],
      "metadata": {
        "id": "2AS6CN95QY89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy file path\n",
        "TRAIN_DATASET_PATH = '/content/drive/MyDrive/Research/Fairness/code/dataset/adult_income/adult.data'\n",
        "TEST_DATASET_PATH = '/content/drive/MyDrive/Research/Fairness/code/dataset/adult_income/adult.test'\n",
        "NAME_DATASET_PATH = '/content/drive/MyDrive/Research/Fairness/code/dataset/adult_income/adult.names'\n",
        "\n",
        "# define the column name of the dataset, required\n",
        "column_name = [\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\n",
        "          \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"]\n",
        "\n",
        "\n",
        "drop_na = True"
      ],
      "metadata": {
        "id": "QswOuDCVQXdj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Nnrbzi6BQczJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rhWMcFl8KVaL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvSiFFTNQNE6",
        "outputId": "e76b47d4-8fd4-4e47-bab5-cf47df9e4061"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "Sv3YZ7UcLlJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "a9k2XM_oASet"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "def adult_feature_engineering(df:DataFrame):\n",
        "  '''\n",
        "  df['native-country']=np.where(df['native-country']==' United-States',1,0)\n",
        "  df['marital-status']=np.where(df['marital-status']==' Married',1,0)\n",
        "  df['workClass']=np.where(df['workClass']==' Private',1,0)\n",
        "  df['sex']=np.where(df['sex']==' Male',1,0)\n",
        "  df['race']=np.where(df['race']==' White',1,0)\n",
        "  '''\n",
        "  df = df.drop(columns=['fnlwgt'])\n",
        "\n",
        "\n",
        "  # income < 50k is 0, otherwise 1\n",
        "  df['sex']=np.where(df['sex']==' Male',1,0)\n",
        "  df['income']=np.where(np.logical_or(df['income']==' <=50K', df['income']==' <=50K.'),0,1)\n",
        "  obj_col = df.select_dtypes(include=['object'])\n",
        "  \n",
        "  # Not sure how to encode education, relationship, and occupation using one-hot\n",
        "\n",
        "  df = df.drop(columns=obj_col.columns)\n",
        "\n",
        "  #df = pd.get_dummies(df,obj_col.columns)\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "F71Jms4DM7Lo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_load_data(TRAIN_DATASET_PATH:str,\n",
        "                TEST_DATASET_PATH:str,\n",
        "                drop_na:bool = True,\n",
        "                column_name:list = None,\n",
        "                ):\n",
        "  assert(column_name != None)\n",
        "  train_dataset = pd.read_csv(TRAIN_DATASET_PATH, index_col=False, header=None,\n",
        "                              names=column_name)\n",
        "  \n",
        "  test_dataset = pd.read_csv(TEST_DATASET_PATH, index_col=False, header=None,\n",
        "                             names=column_name, skiprows=1)\n",
        "  \n",
        "    \n",
        "\n",
        "  print(f'shape of train: {train_dataset.shape}')\n",
        "  print(f'shape of test: {test_dataset.shape}')\n",
        "  \n",
        "  if drop_na == True:\n",
        "    train_dataset = train_dataset.replace({' ?': np.nan}).dropna()\n",
        "    test_dataset = test_dataset.replace({' ?': np.nan}).dropna()\n",
        "\n",
        "  # need ignore_index to recalculate new index\n",
        "  combined_dataset = pd.concat([train_dataset,test_dataset], ignore_index=True)\n",
        "  \n",
        "  int_col = combined_dataset.select_dtypes(include=['int64'])\n",
        "  #print(int_col.columns)\n",
        "\n",
        "\n",
        "  for col in int_col:\n",
        "    mean = combined_dataset[col].mean()\n",
        "    std = combined_dataset[col].std()\n",
        "    combined_dataset[col]=(combined_dataset[col]-mean)/std\n",
        "\n",
        "  #scalar = StandardScaler()\n",
        "  #tmp = scalar.fit_transform(combined_dataset[int_col.columns])\n",
        "  #combined_dataset.drop(int_col, axis=1, inplace=True)\n",
        "  #combined_dataset = np.hstack((combined_dataset.values, tmp))\n",
        "\n",
        "  \n",
        "  combined_dataset = adult_feature_engineering(combined_dataset)\n",
        "\n",
        "  #display(combined_dataset)\n",
        "  #combined_dataset.head()\n",
        "  #combined_dataset.info()\n",
        "\n",
        "  #train_dataset.info()\n",
        "  #test_dataset.info()\n",
        "  #train_dataset.head()\n",
        "  \n",
        "  #print(combined_dataset)\n",
        "  #combined_dataset.head()\n",
        "  index = train_dataset.shape[0]\n",
        "\n",
        "  train_dataset = combined_dataset.iloc[:index,:]\n",
        "  test_dataset = combined_dataset.iloc[index:,:]\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "train_dataset, test_dataset = f_load_data(TRAIN_DATASET_PATH, TEST_DATASET_PATH,  True, column_name)\n",
        "\n",
        "print(f'shape of train: {train_dataset.shape}')\n",
        "print(f'shape of test: {test_dataset.shape}')\n",
        "display(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "g61PRSMCLfmn",
        "outputId": "7bb64c4a-0b6e-495a-ab3d-465a59f09a06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train: (32561, 15)\n",
            "shape of test: (16281, 15)\n",
            "shape of train: (30162, 7)\n",
            "shape of test: (15060, 7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6129ebaf-205a-4cba-ab7c-45dc4e1869c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>education-num</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30162</th>\n",
              "      <td>-1.024972</td>\n",
              "      <td>-1.221545</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.078119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30163</th>\n",
              "      <td>-0.041455</td>\n",
              "      <td>-0.438117</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>0.754693</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30164</th>\n",
              "      <td>-0.798006</td>\n",
              "      <td>0.737026</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.078119</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30165</th>\n",
              "      <td>0.412476</td>\n",
              "      <td>-0.046402</td>\n",
              "      <td>1</td>\n",
              "      <td>0.877457</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.078119</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30166</th>\n",
              "      <td>-0.344075</td>\n",
              "      <td>-1.613260</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.910931</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45217</th>\n",
              "      <td>-0.419730</td>\n",
              "      <td>1.128740</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.078119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45218</th>\n",
              "      <td>0.034201</td>\n",
              "      <td>1.128740</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.411244</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45219</th>\n",
              "      <td>-0.041455</td>\n",
              "      <td>1.128740</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>0.754693</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45220</th>\n",
              "      <td>0.412476</td>\n",
              "      <td>1.128740</td>\n",
              "      <td>1</td>\n",
              "      <td>0.579979</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>-0.078119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45221</th>\n",
              "      <td>-0.268420</td>\n",
              "      <td>1.128740</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.146732</td>\n",
              "      <td>-0.218778</td>\n",
              "      <td>1.587505</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15060 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6129ebaf-205a-4cba-ab7c-45dc4e1869c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6129ebaf-205a-4cba-ab7c-45dc4e1869c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6129ebaf-205a-4cba-ab7c-45dc4e1869c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            age  education-num  sex  ...  capital-loss  hours-per-week  income\n",
              "30162 -1.024972      -1.221545    1  ...     -0.218778       -0.078119       0\n",
              "30163 -0.041455      -0.438117    1  ...     -0.218778        0.754693       0\n",
              "30164 -0.798006       0.737026    1  ...     -0.218778       -0.078119       1\n",
              "30165  0.412476      -0.046402    1  ...     -0.218778       -0.078119       1\n",
              "30166 -0.344075      -1.613260    1  ...     -0.218778       -0.910931       0\n",
              "...         ...            ...  ...  ...           ...             ...     ...\n",
              "45217 -0.419730       1.128740    1  ...     -0.218778       -0.078119       0\n",
              "45218  0.034201       1.128740    0  ...     -0.218778       -0.411244       0\n",
              "45219 -0.041455       1.128740    1  ...     -0.218778        0.754693       0\n",
              "45220  0.412476       1.128740    1  ...     -0.218778       -0.078119       0\n",
              "45221 -0.268420       1.128740    1  ...     -0.218778        1.587505       1\n",
              "\n",
              "[15060 rows x 7 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.index.is_unique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl5TSD6BUOl9",
        "outputId": "d806cfe5-64f3-4af6-9d64-90c6dbc4d32e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Template"
      ],
      "metadata": {
        "id": "x6isP1haSRs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Template model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn\n",
        "\n",
        "class Abernethy_p_sampling(object):\n",
        "  def __init__(\n",
        "      self,\n",
        "      classifier,\n",
        "      p:float,\n",
        "      initial_set_frac:float = 0.3,\n",
        "      origin_train_dataset:DataFrame = None,\n",
        "      origin_test_dataset:DataFrame = None,\n",
        "      protected_label:str = None,\n",
        "      ):\n",
        "    assert(protected_label != None)\n",
        "    assert(0 < p <=1)\n",
        "    assert(0 < initial_set_frac <=1)\n",
        "    self.protected_label = protected_label\n",
        "    self.p = p\n",
        "    self.origin_train_dataset = origin_train_dataset.copy()\n",
        "    self.origin_test_dataset = origin_test_dataset.copy()\n",
        "    self.best_classifier = sklearn.base.clone(classifier)\n",
        "    self.empty_classifier = sklearn.base.clone(classifier)\n",
        "\n",
        "    # construct the initial training set and remove them from the original set\n",
        "    self.trainset = self.origin_train_dataset.sample(frac = initial_set_frac)\n",
        "    self.origin_train_dataset.drop(index=self.trainset.index, inplace=True)\n",
        "    \n",
        "    # Need to reset index to keep everything in order\n",
        "    self.origin_train_dataset.reset_index(drop=True, inplace=True)\n",
        "    self.trainset.reset_index(drop=True, inplace=True)\n",
        "    #display(self.trainset)\n",
        "    #display(self.origin_train_dataset)\n",
        "  \n",
        "  def train(\n",
        "      self,\n",
        "      chosen_metric:str = 'Overall_accuracy',\n",
        "      quiet_mode:bool = True\n",
        "      ):\n",
        "    self.scores_list = []\n",
        "    self.metric_result_list = []\n",
        "    self.run_out_time = {}\n",
        "    best_score = -1\n",
        "\n",
        "    unique_p_label = self.origin_train_dataset[self.protected_label].unique()\n",
        "    for i in unique_p_label:\n",
        "      self.run_out_time[i] = -1\n",
        "\n",
        "    stop_training = False\n",
        "    train_data = self.trainset.copy()\n",
        "    y = train_data['income']\n",
        "    X = train_data.drop('income', axis=1)\n",
        "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)\n",
        "\n",
        "    # fit the initial model and output the prediction\n",
        "    c_classifier = sklearn.base.clone(self.empty_classifier)\n",
        "    c_classifier.fit(X_train, y_train)\n",
        "    y_pred = c_classifier.predict(X_test)\n",
        "\n",
        "    # obtain score and fairness violation\n",
        "    initial_score = c_classifier.score(X_test, y_test)\n",
        "    best_score = initial_score\n",
        "    self.scores_list.append(initial_score)\n",
        "    metric = Fairness_metric(X_test[self.protected_label], true_label=y_test, predict_label=y_pred)\n",
        "    metric.process()\n",
        "    all_violation = metric.calculate_all()\n",
        "    self.metric_result_list.append(all_violation)\n",
        "    c_label = all_violation[chosen_metric][1]\n",
        "    c_vio = all_violation[chosen_metric][2]\n",
        "    if quiet_mode == False: \n",
        "      print(f'Initial Score: {initial_score}, Initial violation: {c_vio}, Initial biased group: {c_label}')\n",
        "    \n",
        "    #display(train_data)\n",
        "    # sample from biased group\n",
        "    t_random_num = np.random.uniform()\n",
        "    if t_random_num < self.p:\n",
        "       smp = self.origin_train_dataset[self.origin_train_dataset[self.protected_label] == c_label].sample()\n",
        "       self.origin_train_dataset.drop(index=smp.index, inplace=True)\n",
        "       self.origin_train_dataset.reset_index(drop=True, inplace=True)\n",
        "       train_data = pd.concat([train_data, smp], ignore_index=True)\n",
        "    else:\n",
        "      smp = self.origin_train_dataset.sample()\n",
        "      self.origin_train_dataset.drop(index=smp.index, inplace=True)\n",
        "      self.origin_train_dataset.reset_index(drop=True, inplace=True)\n",
        "      train_data = pd.concat([train_data, smp], ignore_index=True)\n",
        "\n",
        "    iteration = 1\n",
        "    while stop_training == False:\n",
        "      y = train_data['income']\n",
        "      X = train_data.drop('income', axis=1)\n",
        "      X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y)\n",
        "\n",
        "      # fit the initial model and output the prediction\n",
        "      c_classifier = sklearn.base.clone(self.empty_classifier)\n",
        "      \n",
        "      c_classifier.fit(X_train, y_train)\n",
        "      y_pred = c_classifier.predict(X_test)\n",
        "\n",
        "      # obtain score and fairness violation\n",
        "      c_score = c_classifier.score(X_test, y_test)\n",
        "      self.scores_list.append(c_score)\n",
        "      metric = Fairness_metric(X_test[self.protected_label], true_label=y_test, predict_label=y_pred)\n",
        "      #print(X_test[self.protected_label])\n",
        "      \n",
        "      metric.process()\n",
        "      all_violation = metric.calculate_all()\n",
        "      self.metric_result_list.append(all_violation)\n",
        "      c_label = all_violation[chosen_metric][1]\n",
        "      c_vio = all_violation[chosen_metric][2]\n",
        "      if quiet_mode == False and iteration % 500 == 0: \n",
        "        print(f'Score: {c_score}, violation: {c_vio}, biased group: {c_label}')\n",
        "\n",
        "      #print(all_violation)\n",
        "\n",
        "      \n",
        "      if c_score > best_score:\n",
        "        best_score = c_score\n",
        "        self.best_classifier = c_classifier\n",
        "\n",
        "      # sample from biased group\n",
        "      t_random_num = np.random.uniform()\n",
        "      biased_set = self.origin_train_dataset[self.origin_train_dataset[self.protected_label] == c_label]\n",
        "      if len(biased_set) == 0 and self.run_out_time[c_label] == -1:\n",
        "        print(f'Run out of sample for group {c_label} at iteration {iteration}')\n",
        "        self.run_out_time[c_label] = iteration\n",
        "\n",
        "      if t_random_num < self.p and len(biased_set) != 0:\n",
        "        smp = self.origin_train_dataset[self.origin_train_dataset[self.protected_label] == c_label].sample()\n",
        "        \n",
        "        self.origin_train_dataset.drop(index=smp.index, inplace=True)\n",
        "        self.origin_train_dataset.reset_index(drop=True, inplace=True)\n",
        "        train_data = pd.concat([train_data, smp], ignore_index=True)\n",
        "      else:\n",
        "        smp = self.origin_train_dataset.sample()\n",
        "        self.origin_train_dataset.drop(index=smp.index, inplace=True)\n",
        "        self.origin_train_dataset.reset_index(drop=True, inplace=True)\n",
        "        train_data = pd.concat([train_data, smp], ignore_index=True)\n",
        "\n",
        "      if len(self.origin_train_dataset) == 0:\n",
        "        stop_training = True\n",
        "      iteration += 1\n",
        "\n",
        "\n",
        "    # How to define the best classifier?\n",
        "    return self.best_classifier, self.scores_list, self.metric_result_list\n",
        "  \n",
        "  def predict(\n",
        "      self,\n",
        "      ):\n",
        "    return None\n",
        "  \n",
        "  def save(\n",
        "      self,\n",
        "      path:str):\n",
        "    return None\n",
        "  \n",
        "  def load(\n",
        "      self,\n",
        "      path:str):\n",
        "    return None"
      ],
      "metadata": {
        "id": "XDRdZD3lYLt8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression( max_iter = 100)\n",
        "model = Abernethy_p_sampling(classifier, 0.7, 0.2, train_dataset, test_dataset, 'sex')\n",
        "len(train_dataset)\n",
        "best_classifier, scores_list, metric_result_list = model.train(quiet_mode = False, chosen_metric='Demographic_Parity')\n",
        "# The number of rows do not add up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vxahce5WMA9",
        "outputId": "78e24ab9-314f-4171-f802-367f96c58fc7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Score: 0.8216180371352785, Initial violation: [-0.17165802], Initial biased group: 0\n",
            "Score: 0.8144519289650949, violation: [-0.17060742], biased group: 0\n",
            "Score: 0.8208191126279863, violation: [-0.17771464], biased group: 0\n",
            "Score: 0.8327137546468402, violation: [-0.16847554], biased group: 0\n",
            "Score: 0.8276892430278885, violation: [-0.16419511], biased group: 0\n",
            "Score: 0.8260665729020159, violation: [-0.15567219], biased group: 0\n",
            "Score: 0.8286093888396812, violation: [-0.18115859], biased group: 0\n",
            "Score: 0.8346621905161561, violation: [-0.14910226], biased group: 0\n",
            "Score: 0.8377192982456141, violation: [-0.17266484], biased group: 0\n",
            "Score: 0.8416255222180022, violation: [-0.16656549], biased group: 0\n",
            "Score: 0.8430021754894851, violation: [-0.17564642], biased group: 0\n",
            "Score: 0.8449531737773153, violation: [-0.17842461], biased group: 0\n",
            "Score: 0.8424202127659575, violation: [-0.17107126], biased group: 0\n",
            "Score: 0.8471113948292371, violation: [-0.16178249], biased group: 0\n",
            "Score: 0.8585021485573971, violation: [-0.1790899], biased group: 0\n",
            "Score: 0.8510198049068873, violation: [-0.17491256], biased group: 0\n",
            "Score: 0.8432155074116305, violation: [-0.16082506], biased group: 0\n",
            "Score: 0.8538398018166804, violation: [-0.1726451], biased group: 0\n",
            "Score: 0.8555082490686535, violation: [-0.15340374], biased group: 0\n",
            "Score: 0.8555240793201133, violation: [-0.17679947], biased group: 0\n",
            "Score: 0.8620259481037924, violation: [-0.15863578], biased group: 0\n",
            "Run out of sample for group 0 at iteration 10357\n",
            "Score: 0.8468424872973627, violation: [-0.17401471], biased group: 0\n",
            "Score: 0.853217472992015, violation: [-0.17817652], biased group: 0\n",
            "Score: 0.8462240474560803, violation: [-0.17602305], biased group: 0\n",
            "Score: 0.8413930789707187, violation: [-0.16932942], biased group: 0\n",
            "Score: 0.8376861644722642, violation: [-0.15796429], biased group: 0\n",
            "Score: 0.8440521227406473, violation: [-0.15820108], biased group: 0\n",
            "Score: 0.8425148474298587, violation: [-0.16743161], biased group: 0\n",
            "Score: 0.8432507987220448, violation: [-0.16327201], biased group: 0\n",
            "Score: 0.8423923631404636, violation: [-0.17968443], biased group: 0\n",
            "Score: 0.8362495245340433, violation: [-0.16882403], biased group: 0\n",
            "Score: 0.8294631246516813, violation: [-0.16669787], biased group: 0\n",
            "Score: 0.829520697167756, violation: [-0.16705954], biased group: 0\n",
            "Score: 0.836321675838807, violation: [-0.16485155], biased group: 0\n",
            "Score: 0.8256339006599513, violation: [-0.16876737], biased group: 0\n",
            "Score: 0.8193098759136495, violation: [-0.16233867], biased group: 0\n",
            "Score: 0.836051930758988, violation: [-0.16885327], biased group: 0\n",
            "Score: 0.8252078917332464, violation: [-0.17762271], biased group: 0\n",
            "Score: 0.822627037392138, violation: [-0.16579082], biased group: 0\n",
            "Score: 0.8239072536424878, violation: [-0.18202013], biased group: 0\n",
            "Score: 0.8223724646588814, violation: [-0.17716365], biased group: 0\n",
            "Score: 0.8156188753203678, violation: [-0.16449361], biased group: 0\n",
            "Score: 0.817697543651968, violation: [-0.16540769], biased group: 0\n",
            "Score: 0.8223158506465205, violation: [-0.17667309], biased group: 0\n",
            "Score: 0.8187785388127854, violation: [-0.18226332], biased group: 0\n",
            "Score: 0.8278424225431095, violation: [-0.17387005], biased group: 0\n",
            "Score: 0.8208872967759714, violation: [-0.1639075], biased group: 0\n",
            "Score: 0.8203982121088988, violation: [-0.17238958], biased group: 0\n",
            "Score: 0.8171283963771977, violation: [-0.16471195], biased group: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vio_list = []\n",
        "for dict_i in metric_result_list:\n",
        "  vio_list.append(dict_i['Demographic_Parity'][2])\n",
        "plt.plot(vio_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "KEHTk8w67tmV",
        "outputId": "67c76878-827b-46a7-a4d5-a2ba2e1d5318"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa4104760d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "smp = train_dataset[train_dataset[\"sex\"]== 0].sample()\n",
        "print(smp)\n",
        "index = smp.index\n",
        "print(train_dataset.iloc[index])\n",
        "#print(smp.index)\n",
        "train_dataset.drop(index=smp.index, inplace=True)\n",
        "train_dataset.reset_index(drop=True, inplace=True)\n",
        "print(train_dataset.iloc[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqvR4wiNNAq0",
        "outputId": "b6517d79-a70f-4fc2-a7e1-ae3a514a772d"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            age  ...  native-country_ Yugoslavia\n",
            "12167  0.639442  ...                           0\n",
            "\n",
            "[1 rows x 103 columns]\n",
            "            age  ...  native-country_ Yugoslavia\n",
            "12167  0.639442  ...                           0\n",
            "\n",
            "[1 rows x 103 columns]\n",
            "            age  ...  native-country_ Yugoslavia\n",
            "12167  0.715097  ...                           0\n",
            "\n",
            "[1 rows x 103 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.index.is_unique"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSyc5V-qRwEY",
        "outputId": "91d05dfb-47a8-4789-e52d-141b7eaef789"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fairness Metric"
      ],
      "metadata": {
        "id": "dJws2nDZSZkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Xlte9p0KScjZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#self.true_data = train_dataset[[protected_col,label_col]].to_numpy()\n",
        "# true_data is |protected_label | true_y |\n",
        "\n",
        "class Fairness_metric(object):\n",
        "  def __init__(\n",
        "      self,\n",
        "      protected_label:list,\n",
        "      true_label:list,\n",
        "      predict_label:list,\n",
        "      ):\n",
        "    assert(len(protected_label) == len(true_label))\n",
        "    assert(len(predict_label) == len(true_label))\n",
        "    self.protected_label = np.array(protected_label)\n",
        "    self.predict_label = np.array(predict_label)\n",
        "    self.true_label = np.array(true_label)\n",
        "    self.res_mat = {}\n",
        "    # res_mat: \n",
        "    # key : protected label \n",
        "    # val: [TP, FP, FN, TN]\n",
        "    \n",
        "  def process(self):\n",
        "    for key in np.unique(self.protected_label):\n",
        "      self.res_mat[key] = [0,0,0,0]\n",
        "      # TP, FP, FN, TN\n",
        "    for i in range(len(self.predict_label)):\n",
        "      tmp_prot = self.protected_label[i]\n",
        "      tmp_true = self.true_label[i]\n",
        "      tmp_pred = self.predict_label[i]\n",
        "      if tmp_true == tmp_pred and tmp_true == 1:\n",
        "        # TP\n",
        "        self.res_mat[tmp_prot][0] +=1\n",
        "      elif tmp_true == 1 and tmp_pred == 0:\n",
        "        # FN\n",
        "        self.res_mat[tmp_prot][2] +=1\n",
        "      elif tmp_true == 0 and tmp_pred == 1:\n",
        "        # FP\n",
        "        self.res_mat[tmp_prot][1] +=1\n",
        "      elif tmp_true == 0 and tmp_pred == 0:\n",
        "        # TN\n",
        "        self.res_mat[tmp_prot][3] +=1\n",
        "      else:\n",
        "        print('Incorrect Code')\n",
        "\n",
        "  # This is for two protected labels, can be adapted to multiple protected labels\n",
        "  # output an dict of scores of all labels and a list containing biased group with\n",
        "  # its violation\n",
        "  def Demographic_Parity(\n",
        "      self,\n",
        "      ):\n",
        "    res = {}\n",
        "    # [label : score]\n",
        "    for label, tmp_list in self.res_mat.items():\n",
        "      TP = tmp_list[0]\n",
        "      FP = tmp_list[1]\n",
        "      FN = tmp_list[2]\n",
        "      TN = tmp_list[3]\n",
        "      tot = np.sum(tmp_list)\n",
        "      res[label] = [TP+FP]/tot\n",
        "\n",
        "    min_violation = 99\n",
        "    min_label = None\n",
        "\n",
        "    for label, score in res.items():\n",
        "      for label_2, score_2 in res.items():\n",
        "        if label == label_2:\n",
        "          pass\n",
        "        vio = score-score_2\n",
        "        if vio < min_violation:\n",
        "          min_violation = vio\n",
        "          min_label = label\n",
        "    \n",
        "    assert(min_violation != 99)\n",
        "    assert(-1 <= min_violation <= 0)\n",
        "    assert(min_label != None)\n",
        "    return res , min_label, min_violation\n",
        "  \n",
        "  def Equal_Opportunity(\n",
        "      self,\n",
        "      ):\n",
        "    res = {}\n",
        "    # [label : score]\n",
        "    for label, tmp_list in self.res_mat.items():\n",
        "      \n",
        "      TP = tmp_list[0]\n",
        "      FP = tmp_list[1]\n",
        "      FN = tmp_list[2]\n",
        "      TN = tmp_list[3]\n",
        "      tot = np.sum(tmp_list)\n",
        "      res[label] =[TP]/tot\n",
        "\n",
        "    min_violation = 99\n",
        "    min_label = None\n",
        "\n",
        "    for label, score in res.items():\n",
        "      for label_2, score_2 in res.items():\n",
        "        if label == label_2:\n",
        "          pass\n",
        "        vio = score-score_2\n",
        "        if vio < min_violation:\n",
        "          min_violation = vio\n",
        "          min_label = label\n",
        "    \n",
        "    assert(min_violation != 99)\n",
        "    assert(-1 <= min_violation <= 0)\n",
        "    assert(min_label != None)\n",
        "    return res , min_label, min_violation\n",
        "  \n",
        "  def Equal_Odds(\n",
        "      self,\n",
        "      ):\n",
        "    res = {}\n",
        "    # [label : score]\n",
        "    for label, tmp_list in self.res_mat.items():\n",
        "      TP = tmp_list[0]\n",
        "      FP = tmp_list[1]\n",
        "      FN = tmp_list[2]\n",
        "      TN = tmp_list[3]\n",
        "      tot = np.sum(tmp_list)\n",
        "      res[label] =[TP+FP]/tot\n",
        "\n",
        "    min_violation = 99\n",
        "    min_label = None\n",
        "\n",
        "    for label, score in res.items():\n",
        "      for label_2, score_2 in res.items():\n",
        "        if label == label_2:\n",
        "          pass\n",
        "        vio = score-score_2\n",
        "        if vio < min_violation:\n",
        "          min_violation = vio\n",
        "          min_label = label\n",
        "    \n",
        "    assert(min_violation != 99)\n",
        "    assert(-1 <= min_violation <= 0)\n",
        "    assert(min_label != None)\n",
        "    return res , min_label, min_violation\n",
        "\n",
        "  def Overall_accuracy(\n",
        "      self,\n",
        "      ):\n",
        "    res = {}\n",
        "    # [label : score]\n",
        "    for label, tmp_list in self.res_mat.items():\n",
        "      TP = tmp_list[0]\n",
        "      FP = tmp_list[1]\n",
        "      FN = tmp_list[2]\n",
        "      TN = tmp_list[3]\n",
        "      tot = np.sum(tmp_list)\n",
        "      res[label] =[TP+FN]/tot\n",
        "\n",
        "    min_violation = 99\n",
        "    min_label = None\n",
        "\n",
        "    for label, score in res.items():\n",
        "      for label_2, score_2 in res.items():\n",
        "        if label == label_2:\n",
        "          pass\n",
        "        vio = score-score_2\n",
        "        if vio < min_violation:\n",
        "          min_violation = vio\n",
        "          min_label = label\n",
        "    \n",
        "    assert(min_violation != 99)\n",
        "    assert(-1 <= min_violation <= 0)\n",
        "    assert(min_label != None)\n",
        "    return res , min_label, min_violation\n",
        "\n",
        "\n",
        "  # return dict with {metric_name: (score, highest violation label, violation)}\n",
        "  def calculate_all(self):\n",
        "    return_dict = {}\n",
        "    return_dict['Demographic_Parity'] = self.Demographic_Parity()\n",
        "    return_dict['Equal_Opportunity'] = self.Equal_Opportunity()\n",
        "    return_dict['Equal_Odds'] = self.Equal_Odds()\n",
        "    return_dict['Overall_accuracy'] = self.Overall_accuracy()\n",
        "    return return_dict\n"
      ],
      "metadata": {
        "id": "pmNlFx3OTsrB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "protected_label = [0, 1, 0, 1 , 1]\n",
        "predict_label = [1,0,1,1,0]\n",
        "true_label = [1, 1, 0, 1, 0 ]\n",
        "\n",
        "metric = Fairness_metric(protected_label, true_label, predict_label)\n",
        "metric.process()\n",
        "#print(metric.Overall_accuracy())\n",
        "all_data = metric.calculate_all()\n",
        "c_label = all_data['Overall_accuracy'][2]\n",
        "print(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjsSi8mJnRjA",
        "outputId": "0f4b54d9-018f-4d94-8199-841955482c42"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Demographic_Parity': ({0: array([1.]), 1: array([0.33333333])}, 0, array([0.66666667])), 'Equal_Opportunity': ({0: array([0.5]), 1: array([0.33333333])}, 0, array([0.16666667])), 'Equal_Odds': ({0: array([1.]), 1: array([0.33333333])}, 0, array([0.66666667])), 'Overall_accuracy': ({0: array([0.5]), 1: array([0.66666667])}, 1, array([0.16666667]))}\n"
          ]
        }
      ]
    }
  ]
}